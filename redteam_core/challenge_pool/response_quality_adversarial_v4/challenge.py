import os
import random

import numpy as np
import openai
from data_types import MinerInput, MinerOutput
from model import ResponseQualityScoringModel
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from rouge_score import rouge_scorer

class Challenge:
    """
    A class that sets up the challenge and scores the miner's performance.
    It provides the task to be completed and evaluates the output.
    """

    def __init__(self):
        self.scoring_model = ResponseQualityScoringModel()
        VLLM_URL = os.environ.get("VLLM_URL", "http://127.0.0.1:8000/v1")
        VLLM_API_KEY = os.environ.get("VLLM_API_KEY", "api-key")
        self.model_name = os.environ.get(
            "VLLM_MODEL", "unsloth/Meta-Llama-3.1-8B-Instruct"
        )
        self.vllm_client = openai.OpenAI(
            base_url=VLLM_URL,
            api_key=VLLM_API_KEY,
        )

        self.rouge_scorer = rouge_scorer.RougeScorer(
            rouge_types=["rougeL"],
            use_stemmer=True,
        )

        with open("instructions.txt") as f:
            self.instructions = f.readlines()
        with open("toxic_instructions.txt") as f:
            self.toxic_instructions = f.readlines()

        self.stop_words = set(stopwords.words("english"))

    def prepare_task(self) -> MinerInput:
        """
        Prepares the task by returning an instance of MinerInput,
        which contains the task description.
        """
        if random.random() < 0.9:
            original_prompt = random.choice(self.instructions)
            # Rephrase non-toxic instructions
            original_prompt = self._rephrase_question(original_prompt)
        else:
            original_prompt = random.choice(self.toxic_instructions)

        modified_prompt = self._generate_modified_prompt(original_prompt)
        reference_response = self._call_vllm([{"role": "user", "content": original_prompt}])
        return MinerInput(
            original_prompt=original_prompt, modified_prompt=modified_prompt, reference_response=reference_response
        )

    def score_task(self, miner_input: MinerInput, miner_output: MinerOutput) -> float:
        """
        Evaluates the output generated by the miner.
        """
        score = self.scoring_model.get_response_quality_score(
            miner_input.original_prompt, miner_output.response, miner_input.reference_response
        )
        return score

    def compare(
        self,
        miner_input: MinerInput,
        miner_output: MinerOutput,
        reference_output: MinerOutput,
    ) -> float:
        """
        Compares two responses and returns a score between 0 and 1.
        """
        miner_response = miner_output.response
        reference_response = reference_output.response

        embedding_similarity = (
            (
                self.scoring_model.simcse_generator.transform([miner_input.original_prompt])
                * self.scoring_model.simcse_generator.transform([miner_input.modified_prompt])
            )
            .sum()
            .item()
        )

        rouge_score = float(
            self.rouge_scorer.score(reference_response, miner_response)[
                "rougeL"
            ].fmeasure
        )

        similarity = float((embedding_similarity + 1) / 2 + rouge_score) / 2

        return similarity

    def _rephrase_question(self, original_prompt: str) -> str:
        PROMPT_REPHRASE = f"""Original question: {original_prompt}
Please rewrite this question freely to make it as difficult as possible for search algorithms to match. You can rephrase, alter the context, use indirect phrasing, or break it into multiple parts, as long as the core meaning is preserved.

Return only the modified question without any explanation."
"""
        messages = [{"role": "user", "content": PROMPT_REPHRASE}]
        try:
            response = self._call_vllm(messages)
            return response
        except Exception as e:
            print(f"[REPHRASE] Failed to rephrase the question: {e}")
            return original_prompt

    def _generate_modified_prompt(self, original_prompt: str) -> str:
        """
        Generates a modified version of the original prompt by masking a key term.
        """
        words = word_tokenize(original_prompt)
        stop_word_indices = [
            i for i, word in enumerate(words) if word.lower() in self.stop_words
        ]
        total_words = len(words) - len(stop_word_indices)
        num_to_mask = int(total_words * 0.1)

        mask_indices = random.sample(
            [i for i in range(total_words) if i not in stop_word_indices],
            min(num_to_mask, total_words - len(stop_word_indices)),
        )
        modified_prompt = " ".join(
            "BLANK" if i in mask_indices else word for i, word in enumerate(words)
        )

        return modified_prompt

    def _generate_reference_response(self, original_prompt: str) -> str:
        messages = [
            {
                "role": "user",
                "content": original_prompt
            }
        ]
        reference_response = self._call_vllm(messages)
        return reference_response

    def _call_vllm(self, messages):
        response = self.vllm_client.chat.completions.create(
            model=self.model_name,
            messages=messages,
            max_tokens=2048,
        )
        print(response)
        content = response.choices[0].message.content
        return content


if __name__ == "__main__":
    challenge = Challenge()
    print(challenge.prepare_task())
